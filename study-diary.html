<!DOCTYPE html>
<html lang="en">

<head>
    <script>
        // for search plugin notably
        const base_url = "https://shotwn.github.io/bsc-project/";
    </script>
    <script>
    const darkTheme = window.matchMedia("(prefers-color-scheme: dark)");
    darkTheme.onchange = (e) => {
        if (e.matches) {
            document.documentElement.classList.add("dark")
            localStorage.theme = 'dark';
        } else {
            document.documentElement.classList.remove("dark")
            localStorage.removeItem("theme")
        }
    };

    // On page load. Priotiry to lcaolStorage
    if (localStorage.theme === "dark") {
        document.documentElement.classList.add("dark")
    } else if (localStorage.theme === "light") {
        document.documentElement.classList.remove("dark")
    } else if (darkTheme.matches) {
        document.documentElement.classList.add("dark")
    } else {
        document.documentElement.classList.remove("dark")
    }

    // set the layout based on localStorage
    document.documentElement.classList.add(localStorage.getItem("html-layout") || "layout-fixed");
</script>


    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Study diary - Graduation Thesis Documentation</title>
    


<title>Study diary</title>









<link rel="canonical" href="https://shotwn.github.io/bsc-project/study-diary.html">


<!-- Open Graph (Facebook, LinkedIn) -->

<meta property="og:title" content="Study diary">





<meta property="og:url" content="https://shotwn.github.io/bsc-project/study-diary.html">






<!-- Twitter Card -->

<meta name="twitter:title" content="Study diary">






<!-- JSON-LD Structured Data -->



    <link rel="icon" href="img/favicon.ico">

    <link href="css/base.css" rel="stylesheet">
    <link href="css/geist.css" rel="stylesheet">

    
    

<link id="pygments-light" rel="stylesheet"
    href="css/pygments/shadcn-light.css">
<link id="pygments-dark" rel="stylesheet"
    href="css/pygments/github-dark.css"
    media="(prefers-color-scheme: dark)">


    
    <link href="css/custom.css" rel="stylesheet">

    

    <script src="js/callbacks.js"></script>

    
    <!-- katex -->
<link rel="stylesheet" href="css/katex.min.css">
<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="js/katex.min.js"></script>
<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="js/auto-render.min.js"
    onload='renderMathInElement(document.body, {"macros": {"\\RR": "\\mathbb{R}", "\\dx": "\\mathrm{d}x"}});'></script>
    

    

    

</head>

<body
    class="text-foreground group/body overscroll-none font-sans antialiased [--footer-height:calc(var(--spacing)*14)] [--header-height:calc(var(--spacing)*14)] xl:[--footer-height:calc(var(--spacing)*24)] theme-default">
    <div id="inner-body" class="bg-background relative z-10 flex min-h-svh flex-col">
        <header class="bg-background sticky top-0 z-50 w-full" view-transition-name="header">
    <div class="container-wrapper 3xl:fixed:px-0 px-6">
        <div class="3xl:fixed:container flex h-(--header-height) items-center gap-2 **:data-[slot=separator]:!h-4">
            <button id="menu-button" data-slot="popover-trigger" onclick="onMobileMenuButtonClick(event)"
                class="group whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:text-accent-foreground px-4 py-2 has-[&gt;svg]:px-3 extend-touch-target h-8 touch-manipulation items-center justify-start gap-2.5 !p-0 hover:bg-transparent focus-visible:bg-transparent focus-visible:ring-0 active:bg-transparent dark:hover:bg-transparent flex lg:hidden"
                type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-«Rmplb»"
                data-state="closed">
                <div class="relative flex h-8 w-4 items-center justify-center">
                    <div class="relative size-4">
                        <!-- 16px x 16px -->
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" fill="none" stroke="currentColor"
                            stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                            <line x1="0" x2="16" y1="5" y2="5"
                                class="group-data-[state=open]:translate-y-[2.25px] group-data-[state=open]:-translate-x-[2.25px] group-data-[state=open]:rotate-45 transition-all duration-300 origin-center" />
                            <line x1="0" x2="16" y1="11" y2="11"
                                class="group-data-[state=open]:-translate-y-[2.25px] group-data-[state=open]:-translate-x-[2.25px] group-data-[state=open]:-rotate-45 transition-all duration-300 origin-center" />
                        </svg>
                    </div>

                    <span class="sr-only">Toggle Menu</span>
                </div>
                <span class="flex h-8 items-center text-lg leading-none font-medium">Menu</span>
            </button>
            <a data-slot="button"
                class="items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-5 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 hidden h-8 lg:flex"
                href="https://shotwn.github.io/bsc-project/">
                <span class="size-8 flex flex-row justify-center items-center">
                    

<svg xmlns="http://www.w3.org/2000/svg" width="20px" height="20px" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M15.59 14.37q.159.666.16 1.38a6 6 0 0 1-6 6v-4.8m5.84-2.58a14.98 14.98 0 0 0 6.16-12.12A14.98 14.98 0 0 0 9.631 8.41m5.96 5.96a14.9 14.9 0 0 1-5.841 2.58m-.119-8.54a6 6 0 0 0-7.381 5.84h4.8m2.581-5.84a14.9 14.9 0 0 0-2.58 5.84m2.699 2.7q-.155.032-.311.06a15 15 0 0 1-2.448-2.448l.06-.312m-2.24 2.39a4.49 4.49 0 0 0-1.757 4.306q.341.054.696.054a4.5 4.5 0 0 0 3.61-1.812M16.5 9a1.5 1.5 0 1 1-3 0a1.5 1.5 0 0 1 3 0"/></svg>


                </span>

                
                <h1 class="pr-2">Graduation Thesis Documentation</h1>
                
            </a>
            
            <div class="ml-auto flex items-center gap-2 md:flex-1 md:justify-end">
                <div class="hidden w-full flex-1 md:flex md:w-auto md:flex-none">
                    <button data-slot="dialog-trigger" onclick="onSearchBarClick(event)"
    class="inline-flex items-center gap-2 whitespace-nowrap rounded-md text-sm transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-secondary/80 px-4 py-2 has-[&gt;svg]:px-3 bg-surface text-surface-foreground/60 dark:bg-card relative h-8 w-full justify-start pl-2.5 font-normal shadow-none sm:pr-12 md:w-40 lg:w-56 xl:w-64"
    type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-«R66plb»" data-state="closed">
    <span class="text-muted-foreground hidden lg:inline-flex">Search documentation...</span>
    <span class="text-muted-foreground inline-flex lg:hidden">Search...</span>
    <div class="absolute top-1.5 right-1.5 hidden gap-1 sm:flex">
        <kbd
            class="bg-background text-muted-foreground pointer-events-none flex h-5 items-center justify-center gap-1 rounded border px-1 font-sans text-[0.7rem] font-medium select-none [&amp;_svg:not([class*='size-'])]:size-3">Ctrl</kbd><kbd
            class="bg-background text-muted-foreground pointer-events-none flex h-5 items-center justify-center gap-1 rounded border px-1 font-sans text-[0.7rem] font-medium select-none [&amp;_svg:not([class*='size-'])]:size-3 aspect-square">K</kbd>
    </div>
</button>
<dialog id="search-dialog" onclick="onSearchDialogClick(event)"
    class="fixed top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 bg-background rounded-lg shadow-lg border overflow-hidden p-0">
    <div class="w-lg gap-4">
        <div class="flex h-full w-full flex-col overflow-hidden rounded-md bg-popover text-popover-foreground">
            <div data-slot="command-input-wrapper" class="flex h-9 items-center gap-2 border-b px-3"><svg
                    xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
                    stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
                    class="lucide lucide-search size-4 shrink-0 opacity-50">
                    <circle cx="11" cy="11" r="8"></circle>
                    <path d="m21 21-4.3-4.3"></path>
                </svg>
                <input data-slot="command-input"
                    class="placeholder:text-muted-foreground flex h-10 w-full rounded-md bg-transparent py-3 text-sm outline-hidden disabled:cursor-not-allowed disabled:opacity-50"
                    placeholder="Search documentation..." cmdk-input="" autocomplete="off" autocorrect="off"
                    spellcheck="false" aria-autocomplete="list" role="combobox" aria-expanded="true"
                    aria-controls="radix-«r1t6»" aria-labelledby="radix-«r1t7»" id="radix-«r1t8»" type="text" value=""
                    aria-activedescendant="radix-«r1th»" oninput="onInputHandler(event)">
            </div>
        </div>
        <div id="mkdocs-search-results">
            <!-- search results go there -->
        </div>
    </div>
</dialog>
<script>
    document.removeEventListener("keydown", searchShortcutHandler);
    document.addEventListener("keydown", searchShortcutHandler);
</script>
                </div>
                <div data-orientation="vertical" role="none" data-slot="separator"
                    class="bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px ml-2 hidden lg:block">
                </div>
                <a target="_blank" rel="noreferrer" data-slot="button"
                    class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 rounded-md gap-1.5 px-3 has-[&gt;svg]:px-2.5 h-8 shadow-none"
                    href="https://github.com/shotwn/bsc-project">
                    <svg viewBox="0 0 438.549 438.549">
                        <path fill="currentColor"
                            d="M409.132 114.573c-19.608-33.596-46.205-60.194-79.798-79.8-33.598-19.607-70.277-29.408-110.063-29.408-39.781 0-76.472 9.804-110.063 29.408-33.596 19.605-60.192 46.204-79.8 79.8C9.803 148.168 0 184.854 0 224.63c0 47.78 13.94 90.745 41.827 128.906 27.884 38.164 63.906 64.572 108.063 79.227 5.14.954 8.945.283 11.419-1.996 2.475-2.282 3.711-5.14 3.711-8.562 0-.571-.049-5.708-.144-15.417a2549.81 2549.81 0 01-.144-25.406l-6.567 1.136c-4.187.767-9.469 1.092-15.846 1-6.374-.089-12.991-.757-19.842-1.999-6.854-1.231-13.229-4.086-19.13-8.559-5.898-4.473-10.085-10.328-12.56-17.556l-2.855-6.57c-1.903-4.374-4.899-9.233-8.992-14.559-4.093-5.331-8.232-8.945-12.419-10.848l-1.999-1.431c-1.332-.951-2.568-2.098-3.711-3.429-1.142-1.331-1.997-2.663-2.568-3.997-.572-1.335-.098-2.43 1.427-3.289 1.525-.859 4.281-1.276 8.28-1.276l5.708.853c3.807.763 8.516 3.042 14.133 6.851 5.614 3.806 10.229 8.754 13.846 14.842 4.38 7.806 9.657 13.754 15.846 17.847 6.184 4.093 12.419 6.136 18.699 6.136 6.28 0 11.704-.476 16.274-1.423 4.565-.952 8.848-2.383 12.847-4.285 1.713-12.758 6.377-22.559 13.988-29.41-10.848-1.14-20.601-2.857-29.264-5.14-8.658-2.286-17.605-5.996-26.835-11.14-9.235-5.137-16.896-11.516-22.985-19.126-6.09-7.614-11.088-17.61-14.987-29.979-3.901-12.374-5.852-26.648-5.852-42.826 0-23.035 7.52-42.637 22.557-58.817-7.044-17.318-6.379-36.732 1.997-58.24 5.52-1.715 13.706-.428 24.554 3.853 10.85 4.283 18.794 7.952 23.84 10.994 5.046 3.041 9.089 5.618 12.135 7.708 17.705-4.947 35.976-7.421 54.818-7.421s37.117 2.474 54.823 7.421l10.849-6.849c7.419-4.57 16.18-8.758 26.262-12.565 10.088-3.805 17.802-4.853 23.134-3.138 8.562 21.509 9.325 40.922 2.279 58.24 15.036 16.18 22.559 35.787 22.559 58.817 0 16.178-1.958 30.497-5.853 42.966-3.9 12.471-8.941 22.457-15.125 29.979-6.191 7.521-13.901 13.85-23.131 18.986-9.232 5.14-18.182 8.85-26.84 11.136-8.662 2.286-18.415 4.004-29.263 5.146 9.894 8.562 14.842 22.077 14.842 40.539v60.237c0 3.422 1.19 6.279 3.572 8.562 2.379 2.279 6.136 2.95 11.276 1.995 44.163-14.653 80.185-41.062 108.068-79.226 27.88-38.161 41.825-81.126 41.825-128.906-.01-39.771-9.818-76.454-29.414-110.049z">
                        </path>
                    </svg>
                    
                </a>
                <div data-orientation="vertical" role="none" data-slot="separator"
                    class="bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px 3xl:flex hidden">
                </div>
                <button data-slot="button"
                    class="items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-8 3xl:flex hidden"
                    title="Toggle layout" onclick="toggleLayout(event)">
                    <span class="sr-only">Toggle layout</span>
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
                        stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
                        class="lucide lucide-gallery-horizontal">
                        <path d="M2 3v18"></path>
                        <rect width="12" height="18" x="6" y="3" rx="2"></rect>
                        <path d="M22 3v18"></path>
                    </svg>
                </button>
                <div data-orientation="vertical" role="none" data-slot="separator"
                    class="bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px">
                </div>
                <button data-slot="button"
                    class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 group/toggle extend-touch-target size-8"
                    title="Toggle theme" onclick="onThemeSwitch(event)">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
                        stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
                        class="size-4.5">
                        <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
                        <path d="M12 12m-9 0a9 9 0 1 0 18 0a9 9 0 1 0 -18 0"></path>
                        <path d="M12 3l0 18"></path>
                        <path d="M12 9l4.65 -4.65"></path>
                        <path d="M12 14.3l7.37 -7.37"></path>
                        <path d="M12 19.6l8.85 -8.85"></path>
                    </svg>
                    <span class="sr-only">Toggle theme</span>
                </button>
            </div>
        </div>
    </div>
</header>
        <main class="flex flex-1 flex-col">
            <div class="container-wrapper flex flex-1 flex-col px-2">
                <div data-slot="sidebar-wrapper" style="--sidebar-width: 16rem; --sidebar-width-icon: 3rem;"
                    class="group/sidebar-wrapper has-data-[variant=inset]:bg-sidebar flex w-full 3xl:fixed:container 3xl:fixed:px-3 min-h-min flex-1 items-start px-0 [--sidebar-width:220px] [--top-spacing:0] lg:grid lg:grid-cols-[var(--sidebar-width)_minmax(0,1fr)] lg:[--sidebar-width:240px] lg:[--top-spacing:calc(var(--spacing)*4)]">
                    <div data-slot="sidebar"
                        class="text-sidebar-foreground w-(--sidebar-width) flex-col sticky top-[calc(var(--header-height)+1px)] z-30 hidden h-[calc(100svh-var(--header-height)-var(--footer-height))] bg-transparent lg:flex">
                        <div data-slot="sidebar-content" data-sidebar="content"
                            class="flex min-h-0 flex-1 flex-col gap-2 overflow-auto group-data-[collapsible=icon]:overflow-hidden no-scrollbar px-2 pb-12">
                            <div class="h-(--top-spacing) shrink-0"></div>
                            <div view-transition-name="sidebar" data-slot="sidebar-group" data-sidebar="group"
    class="relative flex w-full min-w-0 flex-col p-2 no-scrollbar">
    

    
    
    

    

    
    

    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/bsc-project/index.html"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Home
        

        

        

        
    </a>
</li>
                
                
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="true" data-sidebar="menu-button"
        data-size="default" href="/bsc-project/study-diary.html"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Study diary
        

        

        

        
    </a>
</li>
                
                
            </ul>
        </div>
    </div>
    

    
    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-label" data-sidebar="group-label"
            class="ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0 text-muted-foreground font-medium">
            Interim reports</div>
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/bsc-project/interim-reports/interim-report-1.html"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Interim report 1
        

        

        

        
    </a>
</li>
                
            </ul>
        </div>
    </div>
    
    


    
</div>
                        </div>
                    </div>
                    <div class="h-full w-full">
                        <div data-slot="docs" class="flex items-stretch text-[1.05rem] sm:text-[15px] xl:w-full">
                            <div class="flex min-w-0 flex-1 flex-col">
                                <div class="h-(--top-spacing) shrink-0"></div>
                                <article class="w-full" view-transition-name="page">
  <div class="flex flex-col gap-2">
    <div class="flex flex-col gap-2">
      <div id="page-header" class="flex items-start justify-between">
        <h1
          class="scroll-m-20 text-4xl font-semibold tracking-tight sm:text-3xl xl:text-4xl"
        >
          Study diary
        </h1>

        <div class="flex items-center gap-2 pt-1.5">
          
<button onclick="fetch(`https://shotwn.github.io/bsc-project/study-diary.md`).then((r) => r.blob()).then((blob) => navigator.clipboard.write([new ClipboardItem({ 'text/plain': blob })]))" 
        data-slot="button" 
        class="cursor-pointer inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-secondary text-secondary-foreground hover:bg-secondary/80 rounded-md gap-1.5 px-3 has-[&>svg]:px-2.5 h-8 shadow-none md:h-7 md:text-[0.8rem]">
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-copy ">
    <path d="M7 7m0 2.667a2.667 2.667 0 0 1 2.667 -2.667h8.666a2.667 2.667 0 0 1 2.667 2.667v8.666a2.667 2.667 0 0 1 -2.667 2.667h-8.666a2.667 2.667 0 0 1 -2.667 -2.667z"></path><path d="M4.012 16.737a2.005 2.005 0 0 1 -1.012 -1.737v-10c0 -1.1 .9 -2 2 -2h10c.75 0 1.158 .385 1.5 1"></path>
</svg>
<span class="max-md:hidden">Copy Page</span>
</button> 
          
          <a
            data-slot="button"
            id="previous-button"
            class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-secondary text-secondary-foreground hover:bg-secondary/80 extend-touch-target size-8 shadow-none md:size-7"
            href="/bsc-project/index.html"
          >
            <svg
              xmlns="http://www.w3.org/2000/svg"
              width="24"
              height="24"
              viewBox="0 0 24 24"
              fill="none"
              stroke="currentColor"
              stroke-width="2"
              stroke-linecap="round"
              stroke-linejoin="round"
              class="tabler-icon tabler-icon-arrow-left"
            >
              <path d="M5 12l14 0"></path>
              <path d="M5 12l6 6"></path>
              <path d="M5 12l6 -6"></path>
            </svg>
            <span class="sr-only">Previous</span>
          </a>
           
          
          <a
            data-slot="button"
            id="next-button"
            class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-secondary text-secondary-foreground hover:bg-secondary/80 extend-touch-target size-8 shadow-none md:size-7"
            href="/bsc-project/interim-reports/interim-report-1.html"
          >
            <span class="sr-only">Next</span>
            <svg
              xmlns="http://www.w3.org/2000/svg"
              width="24"
              height="24"
              viewBox="0 0 24 24"
              fill="none"
              stroke="currentColor"
              stroke-width="2"
              stroke-linecap="round"
              stroke-linejoin="round"
              class="tabler-icon tabler-icon-arrow-right"
            >
              <path d="M5 12l14 0"></path>
              <path d="M13 18l6 -6"></path>
              <path d="M13 6l6 6"></path>
            </svg>
          </a>
          
        </div>
      </div>
      
    </div>
    <div class="flex justify-end items-center">
       
    </div>
  </div>
  <div class="typography w-full flex-1 *:data-[slot=alert]:first:mt-0">
    <p>This is the diary for the study. I try not to edit previous days after they are written, so it will be full of mistakes, dead ends, wrong conclusions, wasted days and so on.</p>
<p>It is mostly for my own reference, so anything but the latest entries should be taken with a few kilos of salt.</p>
<h2 id="initial-research">Initial Research</h2>
<p>I learnt about LHC Olympics<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup>, LLMs, Tokenization, LoRA, HuggingFace Transformers<sup id="fnref:4"><a class="footnote-ref" href="#fn:4">2</a></sup>. I also had a few crash-course sessions about collision events, jet clustering, and other related physics topics. I noticed that I know almost nothing about these topics. But I was able to find some common practices and examples to follow.</p>
<h2 id="2025-10-14">2025-10-14</h2>
<p>I am starting the study diary here. First day of the log is actually the 3rd attempt to have a go at this. This time rather than focusing on the training first, I am focusing on understanding the data.</p>
<h3 id="understanding-the-dataset">Understanding the Dataset</h3>
<p>I was able to successfully unpack the R&amp;D dataset<sup id="fnref:2"><a class="footnote-ref" href="#fn:2">3</a></sup>. It was obvious that the data needed some sort of pre-processing before it can be used in training.</p>
<p>Data consisted of a variable number of particles per event (up to 700). Each particle had 3 features pt, eta, phi. By observing the common practice again, I set required mass parameter to 0. So assumed massless particles.</p>
<p>Using examples from the LHC Olympics 2020, I understood that collimating data to jets was a common way to reduce the complexity of the data. In examples pyjet was used to cluster particles in to jets. But this library was deprecated and the author recommended using fastjet instead. Pyjet was not able to work with current numpy version so I had to use fastjet. </p>
<p>I was able to use fastjet with awkward arrays. But loading the entire dataset in to memory -although serviceable- was not ideal. I created a chunk based data loader, which solved the problem and allowed me to use multiprocessing to speed up the jet clustering.</p>
<p>I read more about jet clustering and found out that anti-kt algorithm was the most common one. I used this algorithm with a radius parameter of 0.5, which was also commonly used in examples.</p>
<p>I also wanted to keep the number of detections (particles) per event, so I added this as an additional feature to the data.</p>
<p>After clustering I had 1 or 2 jets per event with parameters px py pz E.</p>
<p>For each process I created a seperated jsonl file, also keeping signal and background events in seperate files. At the end of a successful process I merge all the files in to 2 files (signal and background).</p>
<p>See ./rd_data_processing.py</p>
<h3 id="preparing-the-dataset-for-training">Preparing the Dataset for Training</h3>
<p>I knew I should merge signal and background files in a shuffled manner for training. I also needed to split the data in to train, validation and test sets. I created a script to do this.</p>
<p>Later on I modified the script to give 1:1 ratio between signal and background events. This is because during training, the LoRA model was learning to always predict the majority class (background) and was not learning anything useful.</p>
<p>Weighted loss function was another option, but I couldn't find a reliable implementation for Transformers just yet. Also I want to have some results in 1:1 ratio first, then I can experiment with weighted loss function later on.</p>
<p>See ./training_data_preparation.py</p>
<h3 id="training-the-model">Training the Model</h3>
<p>I use <code>mistralai/Mistral-7B-Instruct-v0.3</code><sup id="fnref:3"><a class="footnote-ref" href="#fn:3">4</a></sup> model as my initial base model. Mainly because it is a well known open weight model and it is relatively small (7B parameters).</p>
<p>It became apparent early on that with my system only reliable way to inject LHC data to the model was using LoRA fine tuning. This allowed me to train the model with limited resources.</p>
<pre class="codehilite"><code>My system specs:
CPU: AMD Ryzen 7 7700X 8-Core Processor
RAM: 32 GB DDR5 (2x16GB) 6000 MT/s
GPU: NVIDIA GeForce RTX 3070 @ 8 GB GDDR6
SSD: 2 TB NVMe M.2 Samsung 990 Pro
OS: Windows 11 Pro or Ubuntu 24 via WLS2
</code></pre>

<p>At this point I reliant on a lot of LLM help (which can be more miss than hit). I used a lot of examples from other sources, but almost every API there is related to HuggingFace Transformers library was changed in last few months. So I had to do a lot of back and forth to get a working training script. </p>
<p>Most of the parameters I've used in the training script were just copy-paste attempts to start any training going. So as my first training run started I spend a lot of time to research what each parameter meant and if it was suitable for my use case.</p>
<p>See ./train.py</p>
<h3 id="validating-the-model">Validating the Model</h3>
<p>I knew I would need to validate the model during and after training. I created a validation script to do this.</p>
<p>This was also challenging due quantized nature of the LoRA layer. One behavior I am still not sure of is receiving the full prompt echoed back to me as model output. But I was able to get only the added part by the model to validate the model.</p>
<p>See ./validate.py</p>
<h3 id="one-miss-step">One Miss Step</h3>
<p>By some late-night mistake, I decided to to use 1 or 0 instead of signnal or background labels. Which would be more efficient on a more classical ML model. But this was a unworthy effort for an LLM model, since these two words would get tokenized anyway. Not to mention I had to change the validation script and weighted loss function to accomodate this change. Which was a waste of time.</p>
<h3 id="weights-weights-weights">Weights, weights, weights</h3>
<p>On my first iterations I noticed the model was not learning anything useful. It quickly switched to predicting background background background (I had validation token set to 3 during those tests). I first tried to use a compute loss function, but HF Transformers changed this API recently too and it was not reliably working. Even when it worked I wasn't sure if my model was failing because of compute loss weights or something else. So I temporarily switched to 1:1 signal background ratio in the training data. This way I was sure the model was at least seeing both classes equally.</p>
<p>Which is probably not the best way to do it, but at this point I am desperate for any statistically significant results.</p>
<h3 id="let-it-cook">Let it cook</h3>
<p>I finished the day with a training run going.</p>
<h2 id="2025-10-15">2025-10-15</h2>
<h3 id="training-results">Training Results</h3>
<p>Training ran around 9 hours. I was able to get to checkpoint-7700. When I ran the validation I saw a result I did not expect. Model was not predicting anything, at all. </p>
<p>After some heated discussions with LLMs, I realized the model has completely failed. The best result was around checkpoint-2000 giving 76% accuracy. After that model was picking a side "signal" or "background" and sticking to it. Which was dropping accuracy to 50% and staying there. After checkpoint-5000 model was not predicting anything, just echoing the prompt back to me.</p>
<p>I theorized what is happening is likely overfitting. Model was learning the training data too tightly and was not able to generalize to validation data. After a certain point, model was just memorizing the training data then crashing to one side, which was not useful at all.</p>
<h3 id="new-prompt-values">New Prompt &amp; Values</h3>
<p>I changed the prompt to be more specific. Which I didn't before to keep the prompt short but it was obvious now the results became more important than training time. </p>
<p>I also added special tokens [INST] and [/INST] to help the model understand where the instruction starts and ends.</p>
<pre class="codehilite"><code class="language-python">def format_example(example):
    jets = example[&quot;jets&quot;]
    s = &quot;[INST] Classify this event as 'signal' or 'background'.\n&quot;
    s += &quot;jets:\n&quot;
    for i, j in enumerate(jets):
        s += f&quot;  jet{i+1}: px={j['px']:.10f} py={j['py']:.10f} pz={j['pz']:.10f} E={j['E']:.10f}\n&quot;
    s += f&quot;num_particles: {example['num_particles']}[/INST]&quot;

    # HF Trainer expects 'labels'
    return {&quot;input_text&quot;: s, &quot;labels&quot;: example[&quot;type&quot;]}
</code></pre>

<ul>
<li>I tuned the LoRA parameters to r=12, which is 1.5 times more than before. This should give more knobs to turn for LoRA layers. </li>
<li>With this I also set lora_alpha to 48. It was recommended to set lora_alpha to 4 times r. This should help with the scaling of the LoRA layers.</li>
<li>I set lora_dropout from 0.1 to 0.15. Lora dropout randomly drops some of the information during training. This should help with overfitting.</li>
<li>I set learning rate from 2e-4 to 3e-5. This should help with overfitting too. Since model was learning too fast and was overfitting the training data.</li>
<li>I also added an optimizer that uses 8-bit precision. This should help with memory usage but I did not see any significant change in memory usage. I might remove this later if it is not helping.</li>
<li>Finally I doubled gradient_accumulation_steps from 8 to 16. This should help with stability of training. Since my GPU is limited in memory, I can't increase batch size. But appearently increasing gradient accumulation steps is an alternative to increase effective batch size.</li>
</ul>
<p>Checkpoint-500</p>
<pre class="codehilite"><code>Validation Accuracy: 0.69
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.63      0.88      0.74       493
      signal       0.81      0.51      0.62       507

    accuracy                           0.69      1000
   macro avg       0.72      0.69      0.68      1000
weighted avg       0.72      0.69      0.68      1000
</code></pre>

<p>Checkpoint-700</p>
<pre class="codehilite"><code>Validation Accuracy: 0.768
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.86      0.63      0.73       493
      signal       0.72      0.90      0.80       507

    accuracy                           0.77      1000
   macro avg       0.79      0.77      0.76      1000
weighted avg       0.79      0.77      0.76      1000
</code></pre>

<p>Checkpoint-900</p>
<pre class="codehilite"><code>Validation Accuracy: 0.793
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.83      0.72      0.78       493
      signal       0.76      0.86      0.81       507

    accuracy                           0.79      1000
   macro avg       0.80      0.79      0.79      1000
weighted avg       0.80      0.79      0.79      1000
</code></pre>

<p>Checkpoint-1100</p>
<pre class="codehilite"><code>Validation Accuracy: 0.804
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.80      0.81      0.80       493
      signal       0.81      0.80      0.81       507

    accuracy                           0.80      1000
   macro avg       0.80      0.80      0.80      1000
weighted avg       0.80      0.80      0.80      1000
</code></pre>

<p>3am at Checkpoint-1100 before overnight training I've reached 80.4% accuracy. This is a good improvement from previous runs. I will let it train overnight and see if it can increase accuracy further.</p>
<p>This version was promising. So I decided to tag it as v0.1. </p>
<h4 id="about-tokenization-and-floating-point-numbers">About Tokenization and Floating Point Numbers</h4>
<p>I am worried about tokenization of floating point numbers. Since the model doesn't understand the pure numerical values but token representation of them we might be training just a simple memorization (eventhough the model doesn't have access to validation data during training).</p>
<p>Appearently this is a common problem with LLMs. Some solutions like using another layer of numerical model on top of LLM under LoRA is being suggested to me by said LLMs but I first want to see how far I can go with pure LLM approach.</p>
<h2 id="2025-10-16">2025-10-16</h2>
<h3 id="after-overnight-training">After Overnight Training</h3>
<p>Checkpoint-4500</p>
<pre class="codehilite"><code>Validation Accuracy: 0.826
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.82      0.83      0.82       493
      signal       0.83      0.82      0.83       507

    accuracy                           0.83      1000
   macro avg       0.83      0.83      0.83      1000
weighted avg       0.83      0.83      0.83      1000
</code></pre>

<p>Checkpoint-4900</p>
<pre class="codehilite"><code>Validation Accuracy: 0.835
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.86      0.79      0.83       493
      signal       0.81      0.88      0.84       507

    accuracy                           0.83      1000
   macro avg       0.84      0.83      0.83      1000
weighted avg       0.84      0.83      0.83      1000
</code></pre>

<p>Diminishing returns confirmed. I will increase the learning rate slightly and see if it can push the accuracy further.</p>
<ul>
<li>I increased the learning rate from 3e-5 to 1e-4. This should help the model learn faster and hopefully push the model out of local minima.</li>
</ul>
<p>Next idea could be to increase the parameters I offer in the prompt by doing some more numerical analysis on the root data.</p>
<p>Another idea is to extract logits at the output and give the probabilities as part of the output. This way I can see how confident the model is about its predictions. Also have a P score to compare with other models.</p>
<h4 id="increased-learning-rate">Increased learning rate</h4>
<p>Model started as previous but after a point loss and gradient exploded. I paused the training at checkpoint-2300 and ran validation.
Checkpoint-2300</p>
<pre class="codehilite"><code>Validation Accuracy: 0.762
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.84      0.64      0.73       493
      signal       0.72      0.88      0.79       507

    accuracy                           0.76      1000
   macro avg       0.78      0.76      0.76      1000
weighted avg       0.78      0.76      0.76      1000
</code></pre>

<p>Smaller learning rate was better at this point. But maybe the model is trying to escape a local minima. I will let it run a bit more and see if it can recover.</p>
<h2 id="2025-10-17">2025-10-17</h2>
<p>After overnight training
Checkpoint-7100</p>
<pre class="codehilite"><code>Validation Accuracy: 0.43
  background       0.82      0.05      0.10       493
      signal       0.73      0.89      0.80       507
     unknown       0.00      0.00      0.00         0

    accuracy                           0.48      1000
   macro avg       0.51      0.32      0.30      1000
weighted avg       0.77      0.48      0.46      1000
</code></pre>

<p>Catastrophic failure. Model completely failed to learn anything useful. A lot of whitespace predictions too.</p>
<p>Earlier checkpoints from same training session:
Checkpoint-3000</p>
<pre class="codehilite"><code>Validation Accuracy: 0.774
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.78      0.75      0.77       493
      signal       0.76      0.80      0.78       507

    accuracy                           0.77      1000
   macro avg       0.77      0.77      0.77      1000
weighted avg       0.77      0.77      0.77      1000
</code></pre>

<p>Checkpoint-4000</p>
<pre class="codehilite"><code>Validation Accuracy: 0.79
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.77      0.82      0.79       493
      signal       0.82      0.76      0.79       507

    accuracy                           0.79      1000
   macro avg       0.79      0.79      0.79      1000
weighted avg       0.79      0.79      0.79      1000
</code></pre>

<p>Checkpoint-5000</p>
<pre class="codehilite"><code>Validation Accuracy: 0.767
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.71      0.88      0.79       493
      signal       0.85      0.65      0.74       507

    accuracy                           0.77      1000
   macro avg       0.78      0.77      0.76      1000
weighted avg       0.78      0.77      0.76      1000
</code></pre>

<p>Checkpoint-6000</p>
<pre class="codehilite"><code>Validation Accuracy: 0.776
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.71      0.91      0.80       493
      signal       0.88      0.65      0.75       507

    accuracy                           0.78      1000
   macro avg       0.80      0.78      0.77      1000
weighted avg       0.80      0.78      0.77      1000
</code></pre>

<h3 id="prepare-longer-prompt-with-more-features">Prepare longer prompt with more features</h3>
<p>I decided to increase the number of features in the prompt. I calculated additional features.</p>
<p>I also started to use P_T (transverse momentum), psi, eta instead of px, py, pz. Since these might be more relevant for jet physics. I might consider adding lorentz invariants later on too.</p>
<p>First of all I had to increase the max_length from 256 to 512 in both training and validation scripts.</p>
<p>Per Jet Features:
- P_T: Transverse momentum
- eta: Pseudorapidity
- phi: Azimuthal angle
- m: Mass of the jet
- n_particles: Number of particles in the jet
- P_T_lead: Leading particle transverse momentum
- dR: Delta R between jets</p>
<p>Event Level Features:
- n_particles: Total number of particles in the event
- M_jj: Invariant mass of the bi-jet (or n-jet) system</p>
<p>I modified the learning rate back to 3e-5 and restarted the training with new prompt and features.
Also setup r=32 and lora_alpha=128, which should give more capacity to the LoRA layers.</p>
<p>Iterations per second of course decreased due to longer prompt.</p>
<p>But I am becoming more and more skeptical about the pure LLM approach. I think I will need to combine this with a more classical numerical model to get better results.</p>
<p>First results of the new prompt.
Checkpoint-200</p>
<pre class="codehilite"><code>Validation Accuracy: 0.722
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.90      0.49      0.64       494
      signal       0.66      0.94      0.77       506

    accuracy                           0.72      1000
   macro avg       0.78      0.72      0.71      1000
weighted avg       0.78      0.72      0.71      1000
</code></pre>

<p>I think this is a good candidate for overnight training. </p>
<p>Example output:</p>
<pre class="codehilite"><code>&lt;s&gt;[INST] Classify this event as 'signal' or 'background'.
jets:
  jet1: P_T=1306.5740775925 eta=1.0441122764 phi=-0.4744111075 E=2124.1572287046 m=401.5012189251 n_particles=63 P_T_lead=253.7871246338
    dR_jet2=3.33
  jet2: P_T=1411.5709990887 eta=-0.2765506225 phi=2.7480957547 E=1468.9232156050 m=94.2792501634 n_particles=22 P_T_lead=354.7843017578
    dR_jet1=3.33
n_particles: 162 M_jj= 495.7804690885698[/INST]signal
</code></pre>

<p>Since dR_jet1 (angle between jet 1 to jet 2) and dR_jet2 (angle between jet 2 to jet 1) are the same value, it might be better to modify the prompt to only show dR once in the future iterations.</p>
<p>Before overnight training I tagged this version as v0.1.1 and ran until checkpoint-400.</p>
<p>Checkpoint-400</p>
<pre class="codehilite"><code>Validation Accuracy: 0.829
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.76      0.95      0.85       494
      signal       0.94      0.71      0.81       506

    accuracy                           0.83      1000
   macro avg       0.85      0.83      0.83      1000
weighted avg       0.85      0.83      0.83      1000
</code></pre>

<p>I would be excited but I did see 83% accuracy before and training is relatively slow with longer prompt. So I will let it train overnight and see if it can push the accuracy further.</p>
<p>I read more about putting a numberical MLP wrapper on top of the model. This could potentially help in capturing the complex relationships between the features more effectively. </p>
<p>Also all logic behind using LLM was for natural language comprehension and explanations. So soon I will have to try to teach the model to explain its reasoning too.</p>
<p>Checkpoint-500</p>
<pre class="codehilite"><code>Validation Accuracy: 0.839
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.88      0.78      0.83       494
      signal       0.81      0.90      0.85       506

    accuracy                           0.84      1000
   macro avg       0.84      0.84      0.84      1000
weighted avg       0.84      0.84      0.84      1000
</code></pre>

<h2 id="2025-10-18">2025-10-18</h2>
<h3 id="after-overnight-training_1">After Overnight Training</h3>
<p>Checkpoint-2500</p>
<pre class="codehilite"><code>Validation Accuracy: 0.862
Number of unknown predictions: 0
              precision    recall  f1-score   support

  background       0.79      0.99      0.88       494
      signal       0.99      0.74      0.84       506

    accuracy                           0.86      1000
   macro avg       0.89      0.86      0.86      1000
weighted avg       0.89      0.86      0.86      1000
</code></pre>

<p>86% accuracy over 1:1 dataset is showing we are still hitting diminshing returns.</p>
<p>Then I wanted to see what will this model do with the original imbalanced dataset (1:10 signal to background ratio).</p>
<p>Checkpoint-2500 on imbalanced dataset</p>
<pre class="codehilite"><code>Number of correct background predictions: 901 out of 906
Number of correct signal predictions: 63 out of 94
Validation Accuracy: 0.964
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.97      0.99      0.98       906
      signal       0.93      0.67      0.78        94

    accuracy                           0.96      1000
   macro avg       0.95      0.83      0.88      1000
weighted avg       0.96      0.96      0.96      1000
</code></pre>

<p>This is a promising result. 96.4% accuracy on imbalanced dataset with 1:10 signal to background ratio. <strong>BUT my guess is that that 1:10 ratio validation dataset did include too many events from 1:1 training dataset.</strong> So model was able to memorize those events and give good results. I can't change this dataset at the moment since I would need to re-train the model from scratch.</p>
<p>Still we are observing a good recognition considering that the model is purely LLM based. Diminishing returns are still present but I will mark this as a progress.</p>
<p>Perhaps before doing any more changes, I should try my chances on the black-box datasets ?</p>
<h3 id="black-box-dataset-testing">Black Box Dataset Testing</h3>
<p>I prepared the black-box dataset in the same way as the R&amp;D dataset. Jet clustering and feature extraction was done the same way. Because the challenge was done and master key was available, I was able to get the labels for validation.</p>
<p>Checkpoint-2500 on black-box dataset</p>
<pre class="codehilite"><code>Number of correct background predictions: 17581 out of 17979
Number of correct signal predictions: 6 out of 21
Validation Accuracy: 0.9770555555555556
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       1.00      0.98      0.99     17979
      signal       0.01      0.29      0.03        21

    accuracy                           0.98     18000
   macro avg       0.51      0.63      0.51     18000
weighted avg       1.00      0.98      0.99     18000
</code></pre>

<p>Eventhough accuracy is high (97.7%) due to imbalanced dataset, model was only able to identify 6 out of 21 signal events. This is not a good enough result, by comparison we know LHCO contenders were generally estimating more signals than there is, rather than the other way around.</p>
<p>Still it is good news to see the model did not collapse on signal or background only predictions and was able to perform both in 1:1 and 1:10 R&amp;D datasets as well as black-box dataset. This indicates statistically significant learning has taken place.</p>
<p>Perhaps training with imbalanced dataset from start would yield better results on black-box dataset.</p>
<p>Because I enhanced the data processing and received statistically significant results, I tagged this version as v0.1.3. </p>
<h3 id="new-data-processing">New Data Processing</h3>
<p>I modified the data processing to make sure there is no overlap between training and validation/test datasets even between balanced and inbalanced datasets.</p>
<p>I first create the original ratio dataset, then extract a 1:1 ratio dataset from it.</p>
<h3 id="numeric-fusion-adapter">Numeric Fusion Adapter</h3>
<p>After some research, I created a numeric fusion adapter with some LLM help. I go line by line with API docs to understand what was recommended to me and it takes multiple attempts to make everything at least "run". So I am not sure about its parameters yet but it is a start. </p>
<p>This is the numerical layer I was thinking about before. Appearently we can make the model learn numerical features by adding a small MLP layer on top of the LLM model. This method enhances the first token embeddings with numerical features during training.</p>
<p>It is recommended to use this adapter during validation/inference to improve performance on numerical tasks. But this defeats the purpose of LLM only approach for me. Perhaps in the future I can make a reasoning logic. So the model can prepare the data in a way where a simple external regex tool can extract the numerical features and finally push them in to the model to get more precise results.</p>
<p>But even without using the adapter during validation, I hope the model was <em>somehow</em> able to match the tokens with provided numerical values. I kept the validation script as same as it was (only textual prompt input) and I received the following results.</p>
<h4 id="checkpoint-300-with-numeric-fusion-adapter-no-adapter-during-validation">Checkpoint-300 with Numeric Fusion Adapter (no adapter during validation)</h4>
<p>With original ratio dataset (1:10 signal to background)</p>
<pre class="codehilite"><code>Number of correct background predictions: 840 out of 918
Number of correct signal predictions: 59 out of 82
Validation Accuracy: 0.899
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.97      0.92      0.94       918
      signal       0.43      0.72      0.54        82

    accuracy                           0.90      1000
   macro avg       0.70      0.82      0.74      1000
weighted avg       0.93      0.90      0.91      1000
</code></pre>

<p>Eventhough training takes longer with the adapter, likely because my limited computational resources, results seems promising. With checkpoint 300 we are already reaching 89.9% accuracy on imbalanced dataset. </p>
<p>I also ran the same model on 1:1 dataset. </p>
<pre class="codehilite"><code>Number of correct background predictions: 464 out of 501
Number of correct signal predictions: 330 out of 499
Validation Accuracy: 0.794
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.73      0.93      0.82       501
      signal       0.90      0.66      0.76       499

    accuracy                           0.79      1000
   macro avg       0.82      0.79      0.79      1000
weighted avg       0.82      0.79      0.79      1000
</code></pre>

<p>This is surprising. I expected the model to perform better on 1:1 dataset but it is performing better on imbalanced dataset. At least on 1:1 dataset and at Checkpoint-300, accuracy seems same as previous attempts without the adapter.</p>
<p>Still, the day is over. So this setup is the new candidate for overnight training.</p>
<p>I will tag this version as v0.2.0 since it is a significant change in the training and data preparation process.</p>
<h2 id="2025-10-19">2025-10-19</h2>
<h3 id="after-overnight-training-with-numeric-fusion-adapter">After Overnight Training with Numeric Fusion Adapter</h3>
<h4 id="checkpoint-1600">Checkpoint-1600</h4>
<h5 id="11-dataset-at-1000-samples">1:1 Dataset at 1000 samples</h5>
<pre class="codehilite"><code>Number of correct background predictions: 452 out of 501
Number of correct signal predictions: 457 out of 499
Validation Accuracy: 0.909
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.91      0.90      0.91       501
      signal       0.90      0.92      0.91       499

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000
</code></pre>

<p>This is a good improvement. 90.9% accuracy on 1:1 dataset with numeric fusion adapter.</p>
<p>I also ran the same model on imbalanced dataset. With 2000 validation samples (1:10 signal to background ratio).</p>
<h5 id="110-dataset-at-2000-samples">1:10 Dataset at 2000 samples</h5>
<pre class="codehilite"><code>Number of correct background predictions: 1610 out of 1816
Number of correct signal predictions: 170 out of 184
Validation Accuracy: 0.89
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.99      0.89      0.94      1816
      signal       0.45      0.92      0.61       184

    accuracy                           0.89      2000
   macro avg       0.72      0.91      0.77      2000
weighted avg       0.94      0.89      0.91      2000
</code></pre>

<h5 id="black-box-1-dataset-on-original-ratio">Black-box 1 Dataset on Original Ratio</h5>
<pre class="codehilite"><code>Number of correct background predictions: 16744 out of 19982
Number of correct signal predictions: 14 out of 18
Validation Accuracy: 0.8379
WARNING: Number of unknown predictions: 1
              precision    recall  f1-score   support

  background       1.00      0.84      0.91     19982
      signal       0.00      0.78      0.01        18
     unknown       0.00      0.00      0.00         0

    accuracy                           0.84     20000
   macro avg       0.33      0.54      0.31     20000
weighted avg       1.00      0.84      0.91     20000
</code></pre>

<p>These results are promising. 
Model is able to generalize better with numeric fusion adapter eventhough we are not giving seperate numeric input. Previous blackbox test was only able to identify 6 out of 21 signal events. Now it is able to identify 14 out of 18 signal events.</p>
<p>I will tag this version as v0.2.1 before doing some changes to the validation script.</p>
<h3 id="next-steps">Next Steps</h3>
<ul>
<li>Modify validation script to use numeric fusion adapter during validation too. This should improve results further.</li>
</ul>
<p>If numerical adapter during validation improves results significantly, next steps would be:
- Create a regex based numerical extractor to extract numerical features from the prompt.
- Use LLM to format the incoming data in to a format that can be parsed by the numerical extractor.</p>
<h3 id="a-crucial-mistake">A Crucial Mistake</h3>
<p>As I was writing the new validation script, I realized I made a crucial mistake, I did not save the weights for the numeric fusion adapter during training. So I can't use the numeric inputs during validation. I have to re-train the model from scratch to save the adapter weights too.</p>
<p>I fixed the training and validation scripts to save and load the adapter weights respectively. I will start a new training run with the fixed scripts.</p>
<h3 id="two-crucial-mistakes">Two Crucial Mistakes</h3>
<p>As I was about to leave the system for overnight training, I realized that tokenize_example_refined function in training script was not embedding the numerical features at all. So the numeric fusion adapter was not receiving any numerical inputs during training. I am not sure when this mistake was introduced. From git blame it seems like since I added the numeric fusion adapter it never worked as intended. So all the results with numeric fusion adapter might be actually without numerical inputs. But I seem to remember like before yesterday's overnight training I fixed the training script to actually embed the numerical features. </p>
<p>Current I am not sure about the timeline. But <strong>it is safer to assume all results with numeric fusion adapter were just placebo so far.</strong></p>
<h3 id="fixing-the-training-and-validation-scripts">Fixing the Training and Validation Scripts</h3>
<p>I fixed the training script to actually embed the numerical features in to the token embeddings. I also fixed the validation script to load the adapter weights and use numerical features during validation.</p>
<p>Using float16 precision for numerical features caused some challenges. Also Transformers library had a "hidden" API again and I had to go search the source code to find out how to send numerical features to a collator successfully.</p>
<p>Collator should help with more efficient batching of data during training. Plus I added further normalization to the NumericFusionAdapter to keep the numerical features within similar ranges as token embeddings. This should prevent and mismatches between numerical and token embeddings.</p>
<p>This will be v0.2.2 since it is a significant fix. </p>
<h2 id="2025-10-20">2025-10-20</h2>
<h3 id="after-overnight-training-with-fixed-numeric-fusion-adapter">After Overnight Training with Fixed Numeric Fusion Adapter</h3>
<p>I left model to train overnight, but we had a power failure in the area. Eventhough generator kicked in, because I didn't have a UPS, my system shutdown ungracefully. So training was interrupted and reached only checkpoint-1300. In previous attempts by the time model reached checkpoint-1300 it was already plateauing. But with fusion adapter logs indicated that model was still improving.</p>
<div class="table-wrapper"><table>
<thead>
<tr>
<th>Param</th>
<th>Initial Value</th>
<th>Current Value</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>Loss</td>
<td>19.909</td>
<td>14.6236</td>
<td>Decreasing, shows learning</td>
</tr>
<tr>
<td>Grad Norm</td>
<td>34.41</td>
<td>9.92</td>
<td>Decreasing, shows stability improving</td>
</tr>
<tr>
<td>Learning Rate</td>
<td>2.998e-5</td>
<td>2.992e-5</td>
<td>Slightly decreasing, normal behavior</td>
</tr>
</tbody>
</table></div>
<p>So I think I will keep running the training from checkpoint-1300. But first I ran validation to see where we are at.</p>
<h4 id="checkpoint-1300">Checkpoint-1300</h4>
<h5 id="11-dataset-at-1000-samples-numeric-input-enabled">1:1 Dataset at 1000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 504 out of 524
Number of correct signal predictions: 380 out of 476
Validation Accuracy: 0.884
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.84      0.96      0.90       524
      signal       0.95      0.80      0.87       476

    accuracy                           0.88      1000
   macro avg       0.90      0.88      0.88      1000
weighted avg       0.89      0.88      0.88      1000
</code></pre>

<h5 id="110-dataset-at-8000-samples-numeric-input-enabled">1:10 Dataset at 8000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 6989 out of 7250
Number of correct signal predictions: 605 out of 750
Validation Accuracy: 0.94925
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.98      0.96      0.97      7250
      signal       0.70      0.81      0.75       750

    accuracy                           0.95      8000
   macro avg       0.84      0.89      0.86      8000
weighted avg       0.95      0.95      0.95      8000
</code></pre>

<h5 id="110-dataset-at-8000-samples-numeric-input-disabled">1:10 Dataset at 8000 samples &amp; numeric input DISABLED</h5>
<pre class="codehilite"><code>Number of correct background predictions: 6972 out of 7250
Number of correct signal predictions: 609 out of 750
Validation Accuracy: 0.947625
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.98      0.96      0.97      7250
      signal       0.69      0.81      0.74       750

    accuracy                           0.95      8000
   macro avg       0.83      0.89      0.86      8000
weighted avg       0.95      0.95      0.95      8000
</code></pre>

<h5 id="black-box-1-dataset-at-8000-samples-on-original-ratio-numeric-input-enabled">Black-box 1 Dataset at 8000 samples on original ratio &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 7517 out of 7989
Number of correct signal predictions: 6 out of 11
Validation Accuracy: 0.940375
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       1.00      0.94      0.97      7989
      signal       0.01      0.55      0.02        11

    accuracy                           0.94      8000
   macro avg       0.51      0.74      0.50      8000
weighted avg       1.00      0.94      0.97      8000
</code></pre>

<p>Missing almost half of the signal events, but there are only 11 of them.</p>
<h5 id="black-box-1-dataset-at-8000-samples-on-original-ratio-numeric-input-disabled">Black-box 1 Dataset at 8000 samples on original ratio &amp; numeric input DISABLED</h5>
<pre class="codehilite"><code>Number of correct background predictions: 7429 out of 7989
Number of correct signal predictions: 7 out of 11
Validation Accuracy: 0.9295
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       1.00      0.93      0.96      7989
      signal       0.01      0.64      0.02        11

    accuracy                           0.93      8000
   macro avg       0.51      0.78      0.49      8000
weighted avg       1.00      0.93      0.96      8000
</code></pre>

<p>Microscopically better results with numeric input enabled. But overall results seems similar.</p>
<p>I will keep training from checkpoint-1300 and see if we can push the accuracy further. I think the numeric fusion adapter needs to stabilize before showing its true potential or lack thereof.</p>
<h4 id="checkpoint-2200">Checkpoint-2200</h4>
<h5 id="11-dataset-at-1000-samples-numeric-input-enabled_1">1:1 Dataset at 1000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 490 out of 524
Number of correct signal predictions: 412 out of 476
Validation Accuracy: 0.902
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.88      0.94      0.91       524
      signal       0.92      0.87      0.89       476

    accuracy                           0.90      1000
   macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000
</code></pre>

<h5 id="11-dataset-at-1000-samples-numeric-input-disabled">1:1 Dataset at 1000 samples &amp; numeric input DISABLED</h5>
<pre class="codehilite"><code>Number of correct background predictions: 494 out of 524
Number of correct signal predictions: 413 out of 476
Validation Accuracy: 0.907
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.89      0.94      0.91       524
      signal       0.93      0.87      0.90       476

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000
</code></pre>

<p>Better results without numeric input.</p>
<h5 id="110-dataset-at-8000-samples-numeric-input-enabled_1">1:10 Dataset at 8000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 6798 out of 7250
Number of correct signal predictions: 647 out of 750
Validation Accuracy: 0.930625
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.99      0.94      0.96      7250
      signal       0.59      0.86      0.70       750

    accuracy                           0.93      8000
   macro avg       0.79      0.90      0.83      8000
weighted avg       0.95      0.93      0.94      8000
</code></pre>

<h5 id="110-dataset-at-8000-samples-numeric-input-disabled_1">1:10 Dataset at 8000 samples &amp; numeric input DISABLED</h5>
<pre class="codehilite"><code>Number of correct background predictions: 6794 out of 7250
Number of correct signal predictions: 653 out of 750
Validation Accuracy: 0.930875
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.99      0.94      0.96      7250
      signal       0.59      0.87      0.70       750

    accuracy                           0.93      8000
   macro avg       0.79      0.90      0.83      8000
weighted avg       0.95      0.93      0.94      8000
</code></pre>

<p>Slightly better results without numeric input. But negligible difference.</p>
<h5 id="black-box-1-dataset-at-8000-samples-on-original-ratio-numeric-input-enabled_1">Black-box 1 Dataset at 8000 samples on original ratio &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 7166 out of 7989
Number of correct signal predictions: 7 out of 11
Validation Accuracy: 0.896625
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       1.00      0.90      0.95      7989
      signal       0.01      0.64      0.02        11

    accuracy                           0.90      8000
   macro avg       0.50      0.77      0.48      8000
weighted avg       1.00      0.90      0.94      8000
</code></pre>

<h5 id="black-box-1-dataset-at-8000-samples-on-original-ratio-numeric-input-disabled_1">Black-box 1 Dataset at 8000 samples on original ratio &amp; numeric input DISABLED</h5>
<pre class="codehilite"><code>Number of correct background predictions: 7165 out of 7989
Number of correct signal predictions: 7 out of 11
Validation Accuracy: 0.8965
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       1.00      0.90      0.95      7989
      signal       0.01      0.64      0.02        11

    accuracy                           0.90      8000
   macro avg       0.50      0.77      0.48      8000
weighted avg       1.00      0.90      0.94      8000
</code></pre>

<p>No difference with numeric input disabled.</p>
<h3 id="observations">Observations</h3>
<p>With numeric fusion adapter, at least on the validation, numeric input does not seem to improve results. In fact in some cases disabling numeric input yields slightly better results. This might be a failure in my implementation or simply text input does the job well enough.
Maybe numerics fusion adapter needs more training to show its true potential. I will keep training tonight since I don't have any time left to change the code today.</p>
<p>One idea for tomorrow could be to try to create a custom token and tie fusion adapter to that. So we are not messing with the first token embedding, but rather creating our own token that is dedicated to these numerical features. I think this type of an implementation would be cleaner and let us spot any issues more easily. Also it could make the model more flexible, since we can choose to include or exclude the custom token during training and validation.</p>
<p>Final version of this iteration was tagged as v0.2.3.</p>
<h4 id="a-last-minute-change">A last minute change</h4>
<p>Just before starting the training, I decided to modify the numeric adapter to use 2 projection layers with SiLU activation in between instead of simply projecting one linear layer. For this I removed the previous scale and tanh normalization since SiLU should be enough.</p>
<h2 id="2025-10-21">2025-10-21</h2>
<h3 id="after-overnight-training-with-modified-numeric-fusion-adapter">After Overnight Training with Modified Numeric Fusion Adapter</h3>
<h4 id="checkpoint-1500">Checkpoint-1500</h4>
<h5 id="11-dataset-at-1000-samples-numeric-input-enabled_2">1:1 Dataset at 1000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 518 out of 524
Number of correct signal predictions: 335 out of 476
Validation Accuracy: 0.853
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.79      0.99      0.88       524
      signal       0.98      0.70      0.82       476

    accuracy                           0.85      1000
   macro avg       0.88      0.85      0.85      1000
weighted avg       0.88      0.85      0.85      1000
</code></pre>

<h5 id="11-dataset-at-1000-samples-numeric-input-disabled_1">1:1 Dataset at 1000 samples &amp; numeric input DISABLED</h5>
<pre class="codehilite"><code>Number of correct background predictions: 517 out of 524
Number of correct signal predictions: 333 out of 476
Validation Accuracy: 0.85
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.78      0.99      0.87       524
      signal       0.98      0.70      0.82       476

    accuracy                           0.85      1000
   macro avg       0.88      0.84      0.84      1000
weighted avg       0.88      0.85      0.85      1000
</code></pre>

<h5 id="110-dataset-at-8000-samples-numeric-input-enabled_2">1:10 Dataset at 8000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 7127 out of 7250
Number of correct signal predictions: 527 out of 750
Validation Accuracy: 0.95675
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.97      0.98      0.98      7250
      signal       0.81      0.70      0.75       750

    accuracy                           0.96      8000
   macro avg       0.89      0.84      0.86      8000
weighted avg       0.95      0.96      0.96      8000
</code></pre>

<h5 id="110-dataset-at-8000-samples-numeric-input-disabled_2">1:10 Dataset at 8000 samples &amp; numeric input DISABLED</h5>
<pre class="codehilite"><code>Number of correct background predictions: 7127 out of 7250
Number of correct signal predictions: 530 out of 750
Validation Accuracy: 0.957125
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.97      0.98      0.98      7250
      signal       0.81      0.71      0.76       750

    accuracy                           0.96      8000
   macro avg       0.89      0.84      0.87      8000
weighted avg       0.96      0.96      0.96      8000
</code></pre>

<p>Negligible differences again.</p>
<h3 id="found-a-bug">Found a bug !</h3>
<p>I've noticed I am not feeding numerical features properly to the loss function during training. So model is not learning from numerical features at all.</p>
<p>I have fixed the training script to properly feed numerical features to the loss function. Now it is time to restart the training from scratch.</p>
<h3 id="after-bugfix">After bugfix</h3>
<h4 id="checkpoint-400">Checkpoint-400</h4>
<h5 id="11-dataset-at-1000-samples-numeric-input-enabled_3">1:1 Dataset at 1000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 487 out of 524
Number of correct signal predictions: 356 out of 476
Validation Accuracy: 0.843
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.80      0.93      0.86       524
      signal       0.91      0.75      0.82       476

    accuracy                           0.84      1000
   macro avg       0.85      0.84      0.84      1000
weighted avg       0.85      0.84      0.84      1000
</code></pre>

<h5 id="11-dataset-at-1000-samples-numeric-input-disabled_2">1:1 Dataset at 1000 samples &amp; numeric input DISABLED</h5>
<pre class="codehilite"><code>Number of correct background predictions: 71 out of 524
Number of correct signal predictions: 475 out of 476
Validation Accuracy: 0.546
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.99      0.14      0.24       524
      signal       0.51      1.00      0.68       476

    accuracy                           0.55      1000
   macro avg       0.75      0.57      0.46      1000
weighted avg       0.76      0.55      0.45      1000
</code></pre>

<p>Finally ! We are seeing a solid difference with numeric fusion adapter enabled. Even on an early checkpoint like 400. </p>
<p>Note that since now we correctly train with the fusion adapter, we might be making word-only training worse by disabling numeric input. We will need to compare 2 setups at later checkpoints to see the real difference.</p>
<h2 id="2025-10-22">2025-10-22</h2>
<h4 id="checkpoint-2400">Checkpoint 2400</h4>
<h5 id="11-dataset-at-1000-samples-numeric-input-enabled_4">1:1 Dataset at 1000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 466 out of 524
Number of correct signal predictions: 431 out of 476
Validation Accuracy: 0.897
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.91      0.89      0.90       524
      signal       0.88      0.91      0.89       476

    accuracy                           0.90      1000
   macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000
</code></pre>

<h5 id="11-dataset-at-1000-samples-numeric-input-disabled_3">1:1 Dataset at 1000 samples &amp; numeric input DISABLED</h5>
<pre class="codehilite"><code>Number of correct background predictions: 46 out of 524
Number of correct signal predictions: 475 out of 476
Validation Accuracy: 0.521
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.98      0.09      0.16       524
      signal       0.50      1.00      0.66       476

    accuracy                           0.52      1000
   macro avg       0.74      0.54      0.41      1000
weighted avg       0.75      0.52      0.40      1000
</code></pre>

<h5 id="110-dataset-at-8000-samples-numeric-input-enabled_3">1:10 Dataset at 8000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 6395 out of 7250
Number of correct signal predictions: 680 out of 750
Validation Accuracy: 0.884375
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.99      0.88      0.93      7250
      signal       0.44      0.91      0.60       750

    accuracy                           0.88      8000
   macro avg       0.72      0.89      0.76      8000
weighted avg       0.94      0.88      0.90      8000
</code></pre>

<h5 id="110-dataset-at-8000-samples-numeric-input-disabled_3">1:10 Dataset at 8000 samples &amp; numeric input DISABLED</h5>
<pre class="codehilite"><code>Number of correct background predictions: 741 out of 7250
Number of correct signal predictions: 749 out of 750
Validation Accuracy: 0.18625
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       1.00      0.10      0.19      7250
      signal       0.10      1.00      0.19       750

    accuracy                           0.19      8000
   macro avg       0.55      0.55      0.19      8000
weighted avg       0.91      0.19      0.19      8000
</code></pre>

<p>Huge difference again. Model is completely failing without numeric input. But is it more successful than previous attempts without numeric fusion adapter ?</p>
<h5 id="black-box-1-dataset-at-8000-samples-on-original-ratio-numeric-input-enabled_2">Black-box 1 Dataset at 8000 samples on original ratio &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 6440 out of 7989
Number of correct signal predictions: 9 out of 11
Validation Accuracy: 0.806125
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       1.00      0.81      0.89      7989
      signal       0.01      0.82      0.01        11

    accuracy                           0.81      8000
   macro avg       0.50      0.81      0.45      8000
weighted avg       1.00      0.81      0.89      8000
</code></pre>

<h5 id="black-box-1-dataset-at-8000-samples-on-original-ratio-numeric-input-disabled_2">Black-box 1 Dataset at 8000 samples on original ratio &amp; numeric input DISABLED</h5>
<pre class="codehilite"><code>Number of correct background predictions: 847 out of 7989
Number of correct signal predictions: 11 out of 11
Validation Accuracy: 0.10725
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       1.00      0.11      0.19      7989
      signal       0.00      1.00      0.00        11

    accuracy                           0.11      8000
   macro avg       0.50      0.55      0.10      8000
weighted avg       1.00      0.11      0.19      8000
</code></pre>

<h3 id="comparisons">Comparisons</h3>
<p>Up to bugfix (2025-10-21) we can assume models were not trained with numeric features at all. So we can compare the results before and after bugfix to see the impact of numeric fusion adapter.</p>
<p>We will use numeric adapter disabled results from 2025-10-21 as the baseline for comparison.
Precision is calculated as:</p>
<div class="table-wrapper"><table>
<thead>
<tr>
<th>Date</th>
<th>Dataset</th>
<th>Checkpoint</th>
<th>Numeric Input</th>
<th>Accuracy</th>
<th>Background Precision</th>
<th>Signal Precision</th>
<th>F1 Score Signal</th>
<th>F1 Score Background</th>
</tr>
</thead>
<tbody>
<tr>
<td>2025-10-20</td>
<td>1:1 @1000</td>
<td>2200</td>
<td>Disabled</td>
<td>0.907</td>
<td>0.89</td>
<td>0.93</td>
<td>0.90</td>
<td>0.91</td>
</tr>
<tr>
<td>2025-10-21</td>
<td>1:1 @1000</td>
<td>1500</td>
<td>Disabled</td>
<td>0.85</td>
<td>0.78</td>
<td>0.98</td>
<td>0.82</td>
<td>0.87</td>
</tr>
<tr>
<td>2025-10-22</td>
<td>1:1 @1000</td>
<td>2400</td>
<td>Enabled</td>
<td>0.897</td>
<td>0.91</td>
<td>0.88</td>
<td>0.89</td>
<td>0.90</td>
</tr>
<tr>
<td>2025-10-20</td>
<td>1:10 @8000</td>
<td>2200</td>
<td>Disabled</td>
<td>0.930875</td>
<td>0.99</td>
<td>0.59</td>
<td>0.87</td>
<td>0.96</td>
</tr>
<tr>
<td>2025-10-21</td>
<td>1:10 @8000</td>
<td>1500</td>
<td>Disabled</td>
<td>0.957125</td>
<td>0.97</td>
<td>0.81</td>
<td>0.76</td>
<td>0.98</td>
</tr>
<tr>
<td>2025-10-22</td>
<td>1:10 @8000</td>
<td>2400</td>
<td>Enabled</td>
<td>0.884375</td>
<td>0.99</td>
<td>0.44</td>
<td>0.60</td>
<td>0.93</td>
</tr>
<tr>
<td>2025-10-20</td>
<td>Black-box 1 @8000</td>
<td>2200</td>
<td>Disabled</td>
<td>0.8965</td>
<td>1.00</td>
<td>0.01</td>
<td>0.02</td>
<td>0.95</td>
</tr>
<tr>
<td>2025-10-22</td>
<td>Black-box 1 @8000</td>
<td>2400</td>
<td>Enabled</td>
<td>0.806125</td>
<td>1.00</td>
<td>0.01</td>
<td>0.01</td>
<td>0.89</td>
</tr>
</tbody>
</table></div>
<h3 id="observations_1">Observations</h3>
<ul>
<li>On 1:1 dataset, numeric fusion adapter enabled model is performing similarly to the baseline model without numeric input. Slightly worse accuracy but better balance between background and signal precision.</li>
<li>On 1:10 dataset, numeric fusion adapter enabled model is performing worse than the baseline model without numeric input. Significant drop in accuracy and signal precision.</li>
<li>On Black-box dataset, numeric fusion adapter enabled model is performing worse than the baseline model without numeric input. Significant drop in accuracy.</li>
</ul>
<p>So far, numeric fusion adapter does not seem to be helping the model to generalize better. In fact it seems to be hurting the performance on imbalanced and black-box datasets.</p>
<h3 id="next-steps_1">Next Steps</h3>
<ul>
<li>Continue training the model with numeric fusion adapter to see if performance improves with more training.</li>
<li>Perhaps switch training to imbalanced dataset and see if that helps the model to generalize better on black-box dataset.</li>
<li>Investigate alternative methods to incorporate numerical features in to the model.</li>
</ul>
<h2 id="2025-10-23">2025-10-23</h2>
<h3 id="after-2nd-day-of-training">After 2nd day of training</h3>
<h4 id="checkpoint-5300">Checkpoint-5300</h4>
<h5 id="11-dataset-at-1000-samples-numeric-input-enabled_5">1:1 Dataset at 1000 samples &amp; numeric input enabled</h5>
<p>Number of correct background predictions: 493 out of 524
Number of correct signal predictions: 405 out of 476
Validation Accuracy: 0.898
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support</p>
<p>background       0.87      0.94      0.91       524
      signal       0.93      0.85      0.89       476</p>
<pre class="codehilite"><code>accuracy                           0.90      1000
</code></pre>

<p>macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000</p>
<h5 id="11-dataset-at-1000-samples-numeric-input-disabled_4">1:1 Dataset at 1000 samples &amp; numeric input DISABLED</h5>
<p>Number of correct background predictions: 91 out of 524
Number of correct signal predictions: 469 out of 476
Validation Accuracy: 0.56
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support</p>
<p>background       0.93      0.17      0.29       524
      signal       0.52      0.99      0.68       476</p>
<pre class="codehilite"><code>accuracy                           0.56      1000
</code></pre>

<p>macro avg       0.72      0.58      0.49      1000
weighted avg       0.73      0.56      0.48      1000</p>
<p>It is obvious that with numeric input disabled model is failing completely. So I will use numeric input enabled for rest of the tests.</p>
<h5 id="110-dataset-at-8000-samples-numeric-input-enabled_4">1:10 Dataset at 8000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 6797 out of 7250
Number of correct signal predictions: 635 out of 750
Validation Accuracy: 0.929
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.98      0.94      0.96      7250
      signal       0.58      0.85      0.69       750

    accuracy                           0.93      8000
   macro avg       0.78      0.89      0.83      8000
weighted avg       0.95      0.93      0.93      8000
</code></pre>

<h5 id="black-box-1-dataset-at-8000-samples-on-original-ratio-numeric-input-enabled_3">Black-box 1 Dataset at 8000 samples on original ratio &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 7141 out of 7989
Number of correct signal predictions: 8 out of 11
Validation Accuracy: 0.893625
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       1.00      0.89      0.94      7989
      signal       0.01      0.73      0.02        11

    accuracy                           0.89      8000
   macro avg       0.50      0.81      0.48      8000
weighted avg       1.00      0.89      0.94      8000
</code></pre>

<h2 id="2025-10-24">2025-10-24</h2>
<h3 id="after-3rd-day-of-training">After 3rd day of training</h3>
<h4 id="checkpoint-7700">Checkpoint-7700</h4>
<h5 id="11-dataset-at-1000-samples-numeric-input-enabled_6">1:1 Dataset at 1000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 465 out of 524
Number of correct signal predictions: 432 out of 476
Validation Accuracy: 0.897
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.91      0.89      0.90       524
      signal       0.88      0.91      0.89       476

    accuracy                           0.90      1000
   macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000
</code></pre>

<h5 id="110-dataset-at-8000-samples-numeric-input-enabled_5">1:10 Dataset at 8000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 6427 out of 7250
Number of correct signal predictions: 693 out of 750
Validation Accuracy: 0.89
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.99      0.89      0.94      7250
      signal       0.46      0.92      0.61       750

    accuracy                           0.89      8000
   macro avg       0.72      0.91      0.77      8000
weighted avg       0.94      0.89      0.91      8000
</code></pre>

<h5 id="black-box-1-dataset-at-8000-samples-on-original-ratio-numeric-input-enabled_4">Black-box 1 Dataset at 8000 samples on original ratio &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 6589 out of 7989
Number of correct signal predictions: 9 out of 11
Validation Accuracy: 0.82475
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       1.00      0.82      0.90      7989
      signal       0.01      0.82      0.01        11

    accuracy                           0.82      8000
   macro avg       0.50      0.82      0.46      8000
weighted avg       1.00      0.82      0.90      8000
</code></pre>

<p>I will continue training for one more night, but I will change the training dataset to imbalanced 1:10 dataset. Hopefully this will help the model to generalize better on black-box dataset.</p>
<h2 id="2025-10-25">2025-10-25</h2>
<h3 id="switching-to-imbalanced-dataset-for-training">Switching to imbalanced dataset for training</h3>
<p>I have modified the training script to use imbalanced 1:10 dataset for training. I will continue training from checkpoint-7700.</p>
<h4 id="checkpoint-9800">Checkpoint-9800</h4>
<h5 id="11-dataset-at-1000-samples-numeric-input-enabled_7">1:1 Dataset at 1000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 514 out of 524
Number of correct signal predictions: 361 out of 476
Validation Accuracy: 0.875
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.82      0.98      0.89       524
      signal       0.97      0.76      0.85       476

    accuracy                           0.88      1000
   macro avg       0.90      0.87      0.87      1000
weighted avg       0.89      0.88      0.87      1000
</code></pre>

<h5 id="110-dataset-at-8000-samples-numeric-input-enabled_6">1:10 Dataset at 8000 samples &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 7091 out of 7250
Number of correct signal predictions: 573 out of 750
Validation Accuracy: 0.958
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       0.98      0.98      0.98      7250
      signal       0.78      0.76      0.77       750

    accuracy                           0.96      8000
   macro avg       0.88      0.87      0.88      8000
weighted avg       0.96      0.96      0.96      8000
</code></pre>

<h5 id="black-box-1-dataset-at-8000-samples-on-original-ratio-numeric-input-enabled_5">Black-box 1 Dataset at 8000 samples on original ratio &amp; numeric input enabled</h5>
<pre class="codehilite"><code>Number of correct background predictions: 7692 out of 7989
Number of correct signal predictions: 5 out of 11
Validation Accuracy: 0.962125
All predictions classified as 'signal' or 'background'.
              precision    recall  f1-score   support

  background       1.00      0.96      0.98      7989
      signal       0.02      0.45      0.03        11

    accuracy                           0.96      8000
   macro avg       0.51      0.71      0.51      8000
weighted avg       1.00      0.96      0.98      8000
</code></pre>

<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p><a href="https://lhco2020.github.io/homepage/">LHC Olympics 2020 Homepage</a>&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:4">
<p><a href="https://huggingface.co/docs/transformers/en/index">Hugging Face Transformers</a>&#160;<a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p><a href="https://zenodo.org/records/4536377">R&amp;D Dataset</a>&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:3">
<p><a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3">Mistral-7B-Instruct-v0.3</a>&#160;<a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
</ol>
</div>
  </div>
</article>
                                <div class="mx-auto flex flex-wrap h-16 w-full max-w-2xl items-center gap-2 px-4 md:px-0">
    
    <a data-slot="button"
        class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-secondary text-secondary-foreground hover:bg-secondary/80 h-8 rounded-md gap-1.5 px-3 has-[&gt;svg]:px-2.5 shadow-none"
        href="/bsc-project/index.html">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
            stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
            class="tabler-icon tabler-icon-arrow-left ">
            <path d="M5 12l14 0"></path>
            <path d="M5 12l6 6"></path>
            <path d="M5 12l6 -6"></path>
        </svg>
        <span class="max-[500px]:hidden">Home</span>
    </a>
    
    
    <a data-slot="button"
        class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-secondary text-secondary-foreground hover:bg-secondary/80 h-8 rounded-md gap-1.5 px-3 has-[&gt;svg]:px-2.5 ml-auto shadow-none"
        href="/bsc-project/interim-reports/interim-report-1.html">
        <span class="max-[500px]:hidden">Interim report 1</span>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
            stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
            class="tabler-icon tabler-icon-arrow-right ">
            <path d="M5 12l14 0"></path>
            <path d="M13 18l6 -6"></path>
            <path d="M13 6l6 6"></path>
        </svg>
    </a>
    
</div>
                                <dialog id="bottom-sidebar" onclick="onBottomSidebarDialogClick(event)" class="bg-transparent"
    style="position: fixed; left: 0px; top: 0px; transform: translate(0px, 58px); min-width: max-content; --radix-popper-transform-origin: 0% 0px; will-change: transform; z-index: 50; --radix-popper-available-width: 504px; --radix-popper-available-height: 857px; --radix-popper-anchor-width: 72.94999694824219px; --radix-popper-anchor-height: 32px;">
    <div data-side="bottom" data-align="start" data-state="open" role="dialog" data-slot="popover-content"
        class="text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 origin-(--radix-popover-content-transform-origin) border outline-hidden bg-background/90 no-scrollbar h-(--radix-popper-available-height) w-(--radix-popper-available-width) overflow-y-auto rounded-none border-none p-0 shadow-none backdrop-blur duration-100"
        style="--radix-popover-content-transform-origin: var(--radix-popper-transform-origin); --radix-popover-content-available-width: var(--radix-popper-available-width); --radix-popover-content-available-height: var(--radix-popper-available-height); --radix-popover-trigger-width: var(--radix-popper-anchor-width); --radix-popover-trigger-height: var(--radix-popper-anchor-height);"
        tabindex="-1">
        <div class="flex flex-col gap-12 overflow-auto px-6 py-6">
            
            
            

            
            <div class="flex flex-col gap-4">
                <div class="text-muted-foreground text-sm font-medium">Menu</div>
                <div class="flex flex-col gap-3">
                    
                    <a class="text-2xl font-medium" href="index.html">
                        
                        Home
                        
                    </a>
                    
                    <a class="text-2xl font-medium" href="study-diary.html">
                        
                        Study diary
                        
                    </a>
                    
                </div>
            </div>
            

            
            <div class="flex flex-col gap-8">
                
                <div class="flex flex-col gap-4">
                    <div class="text-muted-foreground text-sm font-medium">Interim reports</div>
                    
                    <div class="flex flex-col gap-3">
                        
                        <a class="text-2xl font-medium" href="interim-reports/interim-report-1.html">
                            
                            Interim report 1
                            
                        </a>
                        
                    </div>
                    
                </div>
                
            </div>
            
            

        </div>
    </div>
</dialog>
                            </div>
                            <div
                                class="sticky top-[calc(var(--header-height)+1px)] z-30 ml-auto hidden h-[calc(100svh-var(--header-height)-var(--footer-height))] w-72 flex-col gap-4 overflow-hidden overscroll-none pb-8 xl:flex">
                                <div class="h-(--top-spacing) shrink-0"></div>
                                <div view-transition-name="toc" class="no-scrollbar overflow-y-auto px-8">
    <div class="flex flex-col gap-2 p-4 pt-0 text-sm">
        <p class="text-muted-foreground bg-background sticky top-0 h-6 text-xs">On This Page</p>
        
        
        
        
        <a href="#initial-research"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            Initial Research
        </a>
        

        
        <a href="#2025-10-14"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            2025-10-14
        </a>
        
        
        <a href="#understanding-the-dataset"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Understanding the Dataset
        </a>
        
        <a href="#preparing-the-dataset-for-training"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Preparing the Dataset for Training
        </a>
        
        <a href="#training-the-model"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Training the Model
        </a>
        
        <a href="#validating-the-model"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Validating the Model
        </a>
        
        <a href="#one-miss-step"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            One Miss Step
        </a>
        
        <a href="#weights-weights-weights"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Weights, weights, weights
        </a>
        
        <a href="#let-it-cook"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Let it cook
        </a>
        
        

        
        <a href="#2025-10-15"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            2025-10-15
        </a>
        
        
        <a href="#training-results"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Training Results
        </a>
        
        <a href="#new-prompt-values"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            New Prompt &amp; Values
        </a>
        
        

        
        <a href="#2025-10-16"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            2025-10-16
        </a>
        
        
        <a href="#after-overnight-training"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            After Overnight Training
        </a>
        
        

        
        <a href="#2025-10-17"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            2025-10-17
        </a>
        
        
        <a href="#prepare-longer-prompt-with-more-features"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Prepare longer prompt with more features
        </a>
        
        

        
        <a href="#2025-10-18"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            2025-10-18
        </a>
        
        
        <a href="#after-overnight-training_1"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            After Overnight Training
        </a>
        
        <a href="#black-box-dataset-testing"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Black Box Dataset Testing
        </a>
        
        <a href="#new-data-processing"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            New Data Processing
        </a>
        
        <a href="#numeric-fusion-adapter"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Numeric Fusion Adapter
        </a>
        
        

        
        <a href="#2025-10-19"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            2025-10-19
        </a>
        
        
        <a href="#after-overnight-training-with-numeric-fusion-adapter"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            After Overnight Training with Numeric Fusion Adapter
        </a>
        
        <a href="#next-steps"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Next Steps
        </a>
        
        <a href="#a-crucial-mistake"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            A Crucial Mistake
        </a>
        
        <a href="#two-crucial-mistakes"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Two Crucial Mistakes
        </a>
        
        <a href="#fixing-the-training-and-validation-scripts"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Fixing the Training and Validation Scripts
        </a>
        
        

        
        <a href="#2025-10-20"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            2025-10-20
        </a>
        
        
        <a href="#after-overnight-training-with-fixed-numeric-fusion-adapter"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            After Overnight Training with Fixed Numeric Fusion Adapter
        </a>
        
        <a href="#observations"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Observations
        </a>
        
        

        
        <a href="#2025-10-21"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            2025-10-21
        </a>
        
        
        <a href="#after-overnight-training-with-modified-numeric-fusion-adapter"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            After Overnight Training with Modified Numeric Fusion Adapter
        </a>
        
        <a href="#found-a-bug"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Found a bug !
        </a>
        
        <a href="#after-bugfix"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            After bugfix
        </a>
        
        

        
        <a href="#2025-10-22"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            2025-10-22
        </a>
        
        
        <a href="#checkpoint-2400"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Checkpoint 2400
        </a>
        
        <a href="#comparisons"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Comparisons
        </a>
        
        <a href="#observations_1"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Observations
        </a>
        
        <a href="#next-steps_1"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Next Steps
        </a>
        
        

        
        <a href="#2025-10-23"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            2025-10-23
        </a>
        
        
        <a href="#after-2nd-day-of-training"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            After 2nd day of training
        </a>
        
        

        
        <a href="#2025-10-24"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            2025-10-24
        </a>
        
        
        <a href="#after-3rd-day-of-training"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            After 3rd day of training
        </a>
        
        

        
        <a href="#2025-10-25"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            2025-10-25
        </a>
        
        
        <a href="#switching-to-imbalanced-dataset-for-training"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Switching to imbalanced dataset for training
        </a>
        
        

        
        
        
        

    </div>
    <div class="h-12"></div>
</div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </main>
        <footer view-transition-name="footer"
    class="group-has-[.section-soft]/body:bg-surface/40 3xl:fixed:bg-transparent dark:bg-transparent">
    <div class="container-wrapper px-4 xl:px-6">
        <div class="flex h-(--footer-height) items-center justify-between">
            <div class="text-muted-foreground w-full text-center text-xs leading-loose sm:text-sm">
                
                <a href="https://github.com/asiffer/mkdocs-shadcn">shadcn theme</a> provided by
                <a href="https://github.com/asiffer">@asiffer</a>
            </div>
        </div>
    </div>
</footer>
    </div>
     

<script src="search/main.js"></script>


    

    <script src="js/copy-button.js"></script>
    <script>updatePygmentsStylesheet();</script>
    
    
    
    <script type="speculationrules">
{
  "prerender": [
    {
      "where": {
          "selector_matches": ["#next-button", "#previous-button"],
      }
    }
  ]
}
</script>
</body>

</html>